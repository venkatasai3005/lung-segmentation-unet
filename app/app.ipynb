{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e18b911f-8001-49ee-ac68-050f8fcc8f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚀 Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import gradio as gr\n",
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "691b045c-0327-4f0b-b767-700efc040a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Define custom Dice coefficient and loss\n",
    "def dice_coefficient(y_true, y_pred, smooth=1):\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice_coefficient(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5417e7e-f65e-4428-ad4f-2ed5ef4d2f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Load the model (adjusted path because notebook is inside /notebooks)\n",
    "model = load_model(\n",
    "    \"../models/lung_segmentation_unet.h5\",\n",
    "    custom_objects={\"dice_loss\": dice_loss, \"dice_coefficient\": dice_coefficient},\n",
    "    compile=False,\n",
    "    safe_mode=True\n",
    ")\n",
    "\n",
    "# Optional: recompile for safety\n",
    "model.compile(optimizer='adam', loss=dice_loss, metrics=[dice_coefficient])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ece480c-8f9c-486c-8af0-6f69463a988f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧠 Set target image size used during training\n",
    "IMG_SIZE = (256, 256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59942222-2c05-4972-b525-14857a7e6e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🩻 Segmentation function for Gradio UI\n",
    "def segment_lung(image):\n",
    "    # Convert to grayscale\n",
    "    image_gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    image_resized = cv2.resize(image_gray, IMG_SIZE)\n",
    "    image_array = image_resized.astype(\"float32\") / 255.0\n",
    "    image_input = np.expand_dims(np.expand_dims(image_array, axis=-1), axis=0)\n",
    "\n",
    "    # Predict mask\n",
    "    pred_mask = model.predict(image_input)[0]\n",
    "    pred_mask = (pred_mask > 0.5).astype(np.uint8) * 255\n",
    "\n",
    "    # Convert to RGB for overlay\n",
    "    pred_rgb = cv2.cvtColor(pred_mask, cv2.COLOR_GRAY2RGB)\n",
    "    original_rgb = cv2.cvtColor(image_resized, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # Overlay\n",
    "    overlay = cv2.addWeighted(original_rgb, 0.7, pred_rgb, 0.3, 0)\n",
    "    return overlay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08162a8b-d092-4eb0-8064-996ee33ce2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step\n",
      "Created dataset file at: .gradio\\flagged\\dataset1.csv\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n"
     ]
    }
   ],
   "source": [
    "# 🎯 Launch Gradio App\n",
    "gr.Interface(\n",
    "    fn=segment_lung,\n",
    "    inputs=gr.Image(type=\"numpy\", label=\"Upload Chest X-ray\"),\n",
    "    outputs=gr.Image(label=\"Segmented Lungs\"),\n",
    "    title=\"Lung Segmentation using UNet\",\n",
    "    description=\"Upload a chest X-ray to segment lungs using a trained UNet model.\"\n",
    ").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06311542-e0bb-4e52-aa70-c83a308d4625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
